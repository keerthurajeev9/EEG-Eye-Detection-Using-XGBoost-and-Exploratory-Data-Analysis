```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

There are 3-4 packages you will need to install for today's practical: `install.packages(c("xgboost", "eegkit", "forecast", "tseries", "caret"))` apart from that everything else should already be available on your system. 

If you are using a newer Mac you may have to also install [quartz](https://www.xquartz.org/) to have everything work (do this if you see errors about `X11` during install/execution).

I will endeavour to use explicit imports to make it clear where functions are coming from (functions without `library_name::` are part of base R or a function we've defined in this notebook).

```{r libraries, echo=FALSE}
# Using the same library we used earlier in the course for tabular data because we know it works!
library(xgboost)

# EEG manipulation library in R (although very limited compared to signal processing libraries available in other languages, matlab might actually still be a leader in this specific area)
library(eegkit)

# some time series functions (that we only skim the depths of)
library(forecast)
library(tseries)
library(caret)

# just tidyverse libraries that should already be installed
library(dplyr)
library(reshape2)
library(purrr)
library(ggplot2)
library(caret)
```

## EEG Eye Detection Data

One of the most common types of medical sensor data (and one that we talked about during the lecture) are Electroencephalograms (EEGs).  
These measure mesoscale electrical signals (measured in microvolts) within the brain, which are indicative of a region of neuronal activity.
Typically, EEGs involve an array of sensors (aka channels) placed on the scalp with a high degree of covariance between sensors.

As EEG data can be very large and unwieldy, we are going to use a relatively small/simple dataset today from [this paper](http://ehrai.com/su/pdf/aihls2013.pdf).

This dataset is a 117 second continuous EEG measurement collected from a single person with a device called a "Emotiv EEG Neuroheadset".
In combination with the EEG data collection, a camera was used to record whether person being recorded had their eyes open or closed. 
This was eye status was then manually annotated onto the EEG data with `1` indicated the eyes being closed and `0` the eyes being open.
Measures microvoltages are listed in chronological order with the first measured value at the top of the dataframe.

Let's parse the data directly from the `h2o` library's (which we aren't actually using directly) test data S3 bucket:

```{r parse_data}
eeg_url <- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/eeg/eeg_eyestate_splits.csv"
eeg_data <- read.csv(eeg_url)

# add timestamp
Fs <- 117 / nrow(eeg_data)
eeg_data <- transform(eeg_data, ds = seq(0, 116.99999, by = Fs), eyeDetection = as.factor(eyeDetection))
print(table(eeg_data$eyeDetection))

# split dataset into train, validate, test
eeg_train <- subset(eeg_data, split == 'train', select = -split)
print(table(eeg_train$eyeDetection))

eeg_validate <- subset(eeg_data, split == 'valid', select = -split)
eeg_test <- subset(eeg_data, split == 'test', select = -split)
```

**0** Knowing the `eeg_data` contains 117 seconds of data, inspect the `eeg_data` dataframe and the code above to and determine how many samples per second were taken?

The samples per second is 128

```{r}
samples <- nrow(eeg_data) / 117

cat("Samples:", samples, "\n")
```

**1** How many EEG electrodes/sensors were used?

The number of EEG electrodes/sensors used are 14.

### Exploratory Data Analysis

Now that we have the dataset and some basic parameters let's begin with the ever important/relevant exploratory data analysis.

First we should check there is no missing data!
```{r check_na}
sum(is.na(eeg_data))
```

Great, now we can start generating some plots to look at this data within the time-domain.

First we use `reshape2::melt()` to transform the `eeg_data` dataset from a wide format to a long format expected by `ggplot2`.

Specifically, this converts from "wide" where each electrode has its own column, to a "long" format, where each observation has its own row. 
This format is often more convenient for data analysis and visualization, especially when dealing with repeated measurements or time-series data.

We then use `ggplot2` to create a line plot of electrode intensities per sampling time, with the lines coloured by electrode, and the eye status annotated using dark grey blocks.

```{r plot_data}
melt <- reshape2::melt(eeg_data %>% dplyr::select(-split), id.vars=c("eyeDetection", "ds"), variable.name = "Electrode", value.name = "microvolts")


ggplot2::ggplot(melt, ggplot2::aes(x=ds, y=microvolts, color=Electrode)) + 
  ggplot2::geom_line() + 
  ggplot2::ylim(3500,5000) + 
  ggplot2::geom_vline(ggplot2::aes(xintercept=ds), data=dplyr::filter(melt, eyeDetection==1), alpha=0.005)
```

**2** Do you see any obvious patterns between eyes being open (dark grey blocks in the plot) and the EEG intensities?

The ggplot2 line plot of electrode intensities per sampling period reveals some changes in EEG intensity between open and closed eyes. When the eyes were closed, the EEG intensities appeared to be slightly lower than when the eyes were open, as indicated by the dark grey blocks in the plot.
There is no obvious pattern as such that can be discovered.


**3** Similarly, based on the distribution of eye open/close state over time to anticipate any temporal correlation between these states?

A temporal correlation between these states can be predicted based on the distribution of eye open/close states throughout time. Because the dataset contains discrete intervals of eye open and eye closed states, the transitions between these states are likely to have some temporal dependency or pattern.The temporal correlation between eye open/close states can provide insights into the dynamics of eye behaviour and potentially reveal underlying patterns or rhythms in the data.

From this graph, we can't anticipate as such.

Let's see if we can directly look at the distribution of EEG intensities and see how they related to eye status.


As there are a few extreme outliers in voltage we will use the `dplyr::filter` function to remove values outwith of 3750 to 50003. The function uses the `%in%` operator to check if each value of microvolts is within that range. The function also uses the `dplyr::mutate()` to change the type of the variable eyeDetection from numeric to a factor (R's categorical variable type).

```{r compare_distrib}
melt_train <- reshape2::melt(eeg_train, id.vars=c("eyeDetection", "ds"), variable.name = "Electrode", value.name = "microvolts")

# filter huge outliers in voltage
filt_melt_train <- dplyr::filter(melt_train, microvolts %in% (3750:5000)) %>% dplyr::mutate(eyeDetection=as.factor(eyeDetection))

ggplot2::ggplot(filt_melt_train, ggplot2::aes(y=Electrode, x=microvolts, fill=eyeDetection)) + ggplot2::geom_boxplot()
```



Plots are great but sometimes so it is also useful to directly look at the summary statistics and how they related to eye status.
We will do this by grouping the data based on eye status and electrode before calculating the statistics using the convenient `dplyr::summarise` function.

```{r compare_summary_stats}
filt_melt_train %>% dplyr::group_by(eyeDetection, Electrode) %>% 
    dplyr::summarise(mean = mean(microvolts), median=median(microvolts), sd=sd(microvolts)) %>% 
    dplyr::arrange(Electrode)
```




**4** Based on these analyses are any electrodes consistently more intense or varied when eyes are open?


Based on the "EyeDetection" variable, we can get the following information from mean,median and standard deviation for different electrodes:

1.The standard deviation values for each electrode differ without a discernible pattern.There is no consistent pattern of larger variance when the eyes are open or closed when the standard deviation values are examined.
2.For both eye states, the mean values for each electrode are similar or close. There are no significant differences in mean intensities between open and closed eye states for any of the electrodes (AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4).

There are outliers in the plot and theres electrode F8 which varied.
The mean intensities and standard deviations do not exhibit consistent patterns across the electrodes.We can conclude that no electrode consistently exhibits considerably larger intensity or fluctuation when the eyes are open than closed.


#### Time-Related Trends

As it looks like there may be a temporal pattern in the data we should investigate how it changes over time.  

First we will do a statistical test for stationarity:

```{r convert_to_tseries}
apply(eeg_train, 2, tseries::adf.test)
```


**5** What is stationarity?
 
It is sequence of observations that depicts statistical properties such as mean,variance over a given period of time and is a concept in time-series.
A statistical measure used to find the behavior of the time series signal in such a way that the statiscal components are constant over time .If a  time-series is stationary,it will have:
Constant Mean
Constant Variance
Constant Autocovariance

**6** Why are we interested in stationarity? What do the results of these tests tell us? (ignoring the lack of multiple comparison correction...)

Stationarity is of relevance to us because it simplifies the analysis and modelling of time series data. A stationary time series allows us to make valid predictions and inferences based on statistical attributes calculated from a portion of the data.

The result of the ADF Test has the p-values, test-statistics and critical values.If the test statistic is less than the critical values and the p-value is less than a predetermined significance level (e.g., 0.05), the null hypothesis of non-stationarity is rejected. As a result, the associated variable is most likely stationary.

If the test statistic is more than the critical values or the p-value is greater than the significance threshold, the null hypothesis of non-stationarity is not rejected. This suggests that the associated variable is not likely stationary.

It is used to validate the statiscal result and in case of stationarity ,we have consistent result and in case of non-stationarity there is no statistical coherence.


Then we may want to visually explore patterns of autocorrelation (previous values predicting future ones) and cross-correlation (correlation across channels over time) using `forecast::ggAcf` function.

The ACF plot displays the cross-correlation between each pair of electrode channels and the auto-correlation within the same electrode (the plots along the diagonal.)

Positive autocorrelation indicates that the increase in voltage observed in a given time-interval leads to a proportionate increase in the lagged time interval as well.
Negative autocorrelation indicates the opposite!


```{r correlation}
forecast::ggAcf(eeg_train %>% dplyr::select(-ds))
```




**7** Do any fields show signs of strong autocorrelation (diagonal plots)? Do any pairs of fields show signs of cross-correlation? Provide examples.

In auto correlation, we use the diagonal plots to indicate the relationship between each electrode with itself.
Autocorrelations:
There is a negative correlation between FC6 and FC6.
There is a negative correlation between FC5 and FC5.
There is a negative correlation between F7 and F7.

There are positive correlations between O1 and O1.
There are positive correlations between F4 and F4.
There are positive correlations between T8 and T8.

In cross correlation, we use the plots apart from the diagonals to indicate the relationship between electrode with the other electrodes.
Cross-correlations:
There is a cross-correlation between AF3 and F7.
There is a cross-correlation between AF3 and F3.
Theres cross-correlation between FC5 and F7.




#### Frequency-Space 

We can also explore the data in frequency space by using a Fast Fourier Transform.  
After the FFT we can summarise the distributions of frequencies by their density across the power spectrum.
This will let us see if there any obvious patterns related to eye status in the overall frequency distributions.

```{r fft_open}
eegkit::eegpsd(eeg_train %>% dplyr::filter(eyeDetection == 0) %>% dplyr::select(-eyeDetection, -ds), Fs = Fs, xlab="Eye Open")
```

```{r fft_closed}
eegkit::eegpsd(eeg_train %>% dplyr::filter(eyeDetection == 1) %>% dplyr::select(-eyeDetection, -ds), Fs = Fs, xlab="Eye Closed")
```



**8** Do you see any differences between the power spectral densities for the two eye states? If so, describe them.

The power spectral densities for the two eye states were displayed using the 'eegkit::eegpsd()' function. The function was executed twice, once for open eyes and once for closed eyes, and the resulting plots can be compared to discover any variations in power spectral densities between the two eye states [T8].

There appear to be some variances in the power spectral densities for the two eye states. The power spectral density figure for eye closed, for example, exhibits a peak at roughly 10 Hz that is not evident in the power spectral density map for eye open. Furthermore, the power spectral density figure for open eye exhibits a peak at roughly 20 Hz, which does not appear in the power spectral density plot for closed eye.
For example: When the eyes are open, power is like at 10Hz.

#### Independent Component Analysis

We may also wish to explore whether there are multiple sources of neuronal activity being picked up by the sensors.  
This can be achieved using a process known as independent component analysis (ICA) which decorrelates the channels and identifies the primary sources of signal within the decorrelated matrix.

```{r ica, warning=FALSE}
ica <- eegkit::eegica(eeg_train %>% dplyr::select(-eyeDetection, -ds), nc=3, method='fast', type='time')
mix <- dplyr::as_tibble(ica$M)
mix$eyeDetection <- eeg_train$eyeDetection
mix$ds <- eeg_train$ds

mix_melt <- reshape2::melt(mix, id.vars=c("eyeDetection", "ds"), variable.name = "Independent Component", value.name = "M")


ggplot2::ggplot(mix_melt, ggplot2::aes(x=ds, y=M, color=`Independent Component`)) + 
  ggplot2::geom_line() + 
  ggplot2::geom_vline(ggplot2::aes(xintercept=ds), data=dplyr::filter(mix_melt, eyeDetection==1), alpha=0.005) +
  ggplot2::scale_y_log10()
```



**9** Does this suggest eye opening relates to an independent component of activity across the electrodes?

The ggplot2 line plot of independent component activity across electrodes reveals a difference in activity between open and closed eyes. However, this does not imply that eye opening is related to a separate component of activity across the electrodes. More research would be needed to discover whether there is a link between eye opening and independent component activity.

### Eye Opening Prediction

Now that we've explored the data let's use a simple model to see how well we can predict eye status from the EEGs:

```{r xgboost}
eeg_train_matrix <- as.matrix(dplyr::select(eeg_train, -eyeDetection, -ds))
eeg_train_labels <- as.numeric(eeg_train$eyeDetection) -1

eeg_validate_matrix <- as.matrix(dplyr::select(eeg_validate, -eyeDetection, -ds))
eeg_validate_labels <- as.numeric(eeg_validate$eyeDetection) -1

# Build the xgboost model
model <- xgboost(data = eeg_train_matrix, 
                 label = eeg_train_labels,
                 nrounds = 100,
                 max_depth = 4,
                 eta = 0.1,
                 objective = "binary:logistic")

print(model)
```



**10** Using the `caret` library (or any other library/model type you want such as a neural network) fit another model to predict eye opening.

```{r model2}

set.seed(123)
train_index <- sample(nrow(eeg_data), nrow(eeg_data) * 0.8)
eeg_train <- eeg_data[train_index, ]
eeg_validate <- eeg_data[-train_index, ]

model <- train(eyeDetection ~ ., data = eeg_train, method = "rf")
print(model)

```


**11** Using the best performing of the two models (on the validation dataset) calculate and report the test performance (filling in the code below):

```{r test}
set.seed(123)
train_index <- sample(nrow(eeg_data), nrow(eeg_data) * 0.8)
eeg_train <- eeg_data[train_index, ]
eeg_test <- eeg_data[-train_index, ]

# Fit a random forest model to predict eye opening
library(caret)
model <- train(eyeDetection ~ ., data = eeg_train, method = "rf")

predictions <- predict(model, newdata = eeg_test)

confusionMatrix(predictions, eeg_test$eyeDetection)
```

**12** Describe 2 possible alternative modelling approaches for prediction of eye opening from EEGs we discussed in class but haven't explored in this notebook.

1.RNNs are neural network that can detect temporal relationships in sequential input. They are ideal for analysing time series data such as EEG signals. RNNs may learn patterns and correlations in EEG data across different time steps in the context of predicting eye opening. 

2.Hidden Markov Chain Models are probabilistic representations of temporal dependencies in sequential data. HMMs are distinguished by a collection of hidden states as well as observable emissions.



**13** Find 2 R libraries you could use to implement these approaches.

1.Keras is a popular R library for constructing recurrent neural networks. It's a high-level deep learning library that connects to the massive TensorFlow library. With keras, you can easily build and train various types of RNN architectures such as LSTM and GRU. 

2.Hidden Markov Models is a R library for working with Hidden Markov Models. It includes tools and methods for creating, training, and assessing HMMs. The library supports a variety of HMM types, including discrete, Gaussian, and Gaussian mixtures.


### Optional 

**14** (Optional) As this is the last practical of the course - let me know how you would change future offerings of this course.  What worked and didn't work for you (e.g., in terms of the practicals, tutorials, and lectures)? What would you add or remove from the course? What was the main thing you will take away from this course? This will not impact your marks!

It was a great experience with this course, getting a lot of practicl assignments and supportive tutorials, literature reviews and presentations every week.
Providing real-world datasets, relevant coding exercises, and clear instructions helped us develop practical skills and reinforce their understanding of the material.
There was a lot of  student collaboration and fostering a supportive learning community that has enhanced the overall course experience.

I would definitely take this course again since it provided me a lot of information within a short span of time but I wish the course was a little longer.
